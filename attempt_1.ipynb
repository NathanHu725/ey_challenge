{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer as pc\n",
    "pc.settings.set_subscription_key('xx6tg-6yxmd-gch4d-xf7y7-gk6fz')\n",
    "\n",
    "# Others\n",
    "import requests\n",
    "import rich.table\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where the training labels are stored\n",
    "\n",
    "crop_presence_data = pd.read_csv(\"crop_loc_data.csv\")\n",
    "crop_presence_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel_data(latlong,time_slice,assets):\n",
    "    '''\n",
    "    Returns VV and VH values for a given latitude and longitude \n",
    "    Attributes:\n",
    "    latlong - A tuple with 2 elements - latitude and longitude\n",
    "    time_slice - Timeframe for which the VV and VH values have to be extracted\n",
    "    assets - A list of bands to be extracted\n",
    "    '''\n",
    "\n",
    "    latlong=latlong.replace('(','').replace(')','').replace(' ','').split(',')\n",
    "\n",
    "    # Creating bounding box\n",
    "    box_size_deg = 0.10\n",
    "    min_lon = float(latlong[1]) - box_size_deg/2\n",
    "    min_lat = float(latlong[0]) - box_size_deg/2\n",
    "    max_lon = float(latlong[1]) + box_size_deg/2\n",
    "    max_lat = float(latlong[0]) + box_size_deg/2\n",
    "    bbox_of_interest = (min_lon, min_lat, max_lon, max_lat)\n",
    "    # bbox_of_interest = (float(latlong[1]) - .0000000000001, float(latlong[0]) - .0000000000001, float(latlong[1]) + .0000000000001, float(latlong[0]) + .0000000000001)\n",
    "    print(bbox_of_interest)\n",
    "    time_of_interest = time_slice\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"], bbox=bbox_of_interest, datetime=time_of_interest\n",
    "    )\n",
    "    items = list(search.get_all_items())\n",
    "    data = stac_load([items[0]], patch_url=pc.sign, bbox=bbox_of_interest).isel(time=0)\n",
    "    vh = data[\"vh\"].astype(\"float\").values.tolist()[0][0]\n",
    "    vv = data[\"vv\"].astype(\"float\").values.tolist()[0][0]\n",
    "    return vh,vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function call to extract VV,VH Values\n",
    "time_slice = \"2020-03-20/2020-03-21\"\n",
    "assests = ['vh','vv', 'nir']\n",
    "vh_vv = []\n",
    "for coordinates in tqdm(crop_presence_data['Latitude and Longitude']):\n",
    "    print(coordinates)\n",
    "    vh_vv.append(get_sentinel_data(coordinates,time_slice,assests))\n",
    "vh_vv_data = pd.DataFrame(vh_vv,columns =['vh','vv', 'nir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data = pd.concat([crop_presence_data,vh_vv_data], axis=1)\n",
    "crop_data = crop_data[['vh', 'vv', 'nir', 'Class of Land']]\n",
    "crop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crop_data.drop(columns=['Class of Land']).values\n",
    "y = crop_data ['Class of Land'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y,random_state=40)\n",
    "X_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2010312f1bdf40180751013289d36d51075493d82ea5b9a4876b773a8ec1e2d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
